{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "credentials = DefaultAzureCredential()\n",
        "\n",
        "ml_client = MLClient(\n",
        "    credential=credentials,\n",
        "    subscription_id=\"a9ea30e6-5728-4375-ac04-cbe4918c3def\",\n",
        "    resource_group_name=\"rg-training\",\n",
        "    workspace_name=\"ws-training\"\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1720239777015
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ws = ml_client.workspaces.get(\"ws-training\")\n",
        "print(ws.location, \":\", ws.resource_group)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "eastus : rg-training\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720239777820
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Access registered data asset\n",
        "credit_data = ml_client.data.get(name=\"credit-card\", version=\"initial\")\n",
        "print(f\"Data asset URI: {credit_data.path}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Data asset URI: azureml://subscriptions/a9ea30e6-5728-4375-ac04-cbe4918c3def/resourcegroups/rg-training/workspaces/ws-training/datastores/workspaceblobstore/paths/LocalUpload/f4315d633696cbc4576bf53f59a90e8f/default_of_credit_card_clients.csv\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720239778108
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create job environment for pipeline steps"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "dependencies_dir = \"./dependencies\"\n",
        "os.makedirs(dependencies_dir, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720239778202
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {dependencies_dir}/conda.yaml\n",
        "name: model-env\n",
        "channels: \n",
        "    - conda-forge\n",
        "dependencies:\n",
        "    - python=3.8\n",
        "    - numpy=1.21.2\n",
        "    - pip=21.2.4\n",
        "    - scikit-learn=0.24.2\n",
        "    - scipy=1.7.1\n",
        "    - pandas>=1.1,<1.2\n",
        "    - pip:\n",
        "        - inference-schema[numpy-support]==1.3.0\n",
        "        - xlrd==2.0.1\n",
        "        - mlflow==2.4.1\n",
        "        - azureml-mlflow==1.51.0"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting ./dependencies/conda.yaml\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Environment\n",
        "\n",
        "custom_env_name = \"aml-scikit-learn\"\n",
        "\n",
        "pipeline_job_env = Environment(\n",
        "    name=custom_env_name,\n",
        "    description=\"Custom environment for Credit Card Defaults pipeline\",\n",
        "    tags={\"scikit-learn\": \"0.24.2\"},\n",
        "    conda_file=os.path.join(dependencies_dir, \"conda.yaml\"),\n",
        "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
        "    version=\"0.3.0\",\n",
        ")\n",
        "\n",
        "pipeline_job_env = ml_client.environments.create_or_update(pipeline_job_env)\n",
        "\n",
        "print(\n",
        "    f\"Environment with name {pipeline_job_env.name} is registered to workspace, the environment version is {pipeline_job_env.version}\"\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Environment with name aml-scikit-learn is registered to workspace, the environment version is 0.3.0\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720239810284
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build the training pipeline"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_prep_src_dir = \"./components/data_prep\"\n",
        "os.makedirs(data_prep_src_dir, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720239810366
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# component 1: data prep "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {data_prep_src_dir}/data_prep.py\n",
        "import os\n",
        "import argparse\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import logging\n",
        "import mlflow\n",
        "\n",
        "def main():\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--data\", type=str, help=\"path to input data\")\n",
        "    parser.add_argument(\"--test_train_ratio\", type=float, required=False, default=0.25)\n",
        "    parser.add_argument(\"--train_data\", type=str, help=\"path to train data\")\n",
        "    parser.add_argument(\"--test_data\", type=str, help=\"path to test data\")\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    mlflow.start_run()\n",
        "\n",
        "    print(\" \".join(f\"{k}={v}\" for k, v in vars(args).items()))\n",
        "    print(\"input data:\", args.data)\n",
        "\n",
        "    credit_df = pd.read_csv(args.data, header=1, index_col=0)\n",
        "\n",
        "    mlflow.log_metric(\"num_samples\", credit_df.shape[0])\n",
        "    mlflow.log_metric(\"num_features\", credit_df.shape[1] - 1)\n",
        "\n",
        "    credit_train_df, credit_test_df = train_test_split(\n",
        "        credit_df,\n",
        "        test_size=args.test_train_ratio\n",
        "    )\n",
        "\n",
        "    credit_train_df.to_csv(os.path.join(args.train_data, \"data.csv\"), index=False)\n",
        "    credit_test_df.to_csv(os.path.join(args.test_data, \"data.csv\"), index=False)\n",
        "\n",
        "    mlflow.end_run()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting ./components/data_prep/data_prep.py\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create an Azure Machine Learning Component\n",
        "\n",
        "from azure.ai.ml import command\n",
        "from azure.ai.ml import Input, Output\n",
        "\n",
        "data_prep_component = command(\n",
        "    name=\"data_prep_credit_defaults\",\n",
        "    display_name=\"Data preperation for training\",\n",
        "    description=\"reads a .xl input, split the input data to train and test\",\n",
        "    inputs={\n",
        "        \"data\": Input(type=\"uri_folder\"),\n",
        "        \"test_train_ratio\": Input(type=\"number\")\n",
        "    },\n",
        "    outputs=dict(\n",
        "        train_data=Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
        "        test_data=Output(type=\"uri_folder\", mode=\"rw_mount\")\n",
        "    ),\n",
        "    code=data_prep_src_dir,\n",
        "    command=\"\"\"python data_prep.py \\\n",
        "    --data ${{inputs.data}} --test_train_ratio ${{inputs.test_train_ratio}} \\\n",
        "    --train_data ${{outputs.train_data}} --test_data ${{outputs.test_data}} \\\n",
        "    \"\"\",\n",
        "    environment=f\"{pipeline_job_env.name}:{pipeline_job_env.version}\"\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720239810552
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Optionally, register the component in the workspace for future reuse\n",
        "\n",
        "data_prep_component = ml_client.create_or_update(data_prep_component.component)\n",
        "\n",
        "print(\n",
        "    f\"Component {data_prep_component.name} with version {data_prep_component.version} is registered\"\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Component data_prep_credit_defaults with version 2024-07-06-04-23-47-7685213 is registered\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720239828711
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# component 2: training"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "train_src_dir = \"./components/train\"\n",
        "os.makedirs(train_src_dir, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720239828887
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {train_src_dir}/train.py\n",
        "import argparse\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import os\n",
        "import pandas as pd\n",
        "import mlflow\n",
        "\n",
        "def select_first_file(path):\n",
        "    files = os.listdir(path)\n",
        "    return os.path.join(path, files[0])\n",
        "\n",
        "mlflow.start_run()\n",
        "mlflow.sklearn.autolog()\n",
        "\n",
        "os.makedirs(\"./outputs\", exist_ok=True)\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--train_data\", type=str, help=\"path to train data\")\n",
        "    parser.add_argument(\"--test_data\", type=str, help=\"path to test data\")\n",
        "    parser.add_argument(\"--n_estimators\", required=False, default=100, type=int)\n",
        "    parser.add_argument(\"--learning_rate\", required=False, default=0.1, type=float)\n",
        "    parser.add_argument(\"--registered_model_name\", type=str, help=\"model name\")\n",
        "    parser.add_argument(\"--model\", type=str, help=\"path to model file\")\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    train_df = pd.read_csv(select_first_file(args.train_data))\n",
        "    y_train = train_df.pop(\"default payment next month\")\n",
        "    X_train = train_df.values\n",
        "    \n",
        "    test_df = pd.read_csv(select_first_file(args.test_data))\n",
        "    y_test = test_df.pop(\"default payment next month\")\n",
        "    X_test = test_df.values\n",
        "\n",
        "    print(f\"Training with data of shape {X_train.shape}\")\n",
        "\n",
        "    clf = GradientBoostingClassifier(\n",
        "        n_estimators=args.n_estimators, \n",
        "        learning_rate=args.learning_rate\n",
        "    )\n",
        "\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = clf.predict(X_test)\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    print(\"Registering the model via MLFlow\")\n",
        "\n",
        "    mlflow.sklearn.log_model(\n",
        "        sk_model=clf,\n",
        "        registered_model_name=args.registered_model_name,\n",
        "        artifact_path=args.registered_model_name\n",
        "    )\n",
        "\n",
        "    mlflow.sklearn.save_model(\n",
        "        sk_model=clf,\n",
        "        path=os.path.join(args.model, \"trained_model\")\n",
        "    )\n",
        "\n",
        "    mlflow.end_run()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting ./components/train/train.py\n"
        }
      ],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {train_src_dir}/train.yml\n",
        "name: train_credit_defaults_model\n",
        "display_name: Train Credit Defaults Model\n",
        "type: command\n",
        "inputs:\n",
        "    train_data:\n",
        "        type: uri_folder\n",
        "    test_data:\n",
        "        type: uri_folder\n",
        "    learning_rate:\n",
        "        type: number\n",
        "    registered_model_name:\n",
        "        type: string\n",
        "outputs:\n",
        "    model:\n",
        "        type: uri_folder\n",
        "code: .\n",
        "environment: \n",
        "    # for this step, we'll use an AzureML curate environment\n",
        "    azureml:AzureML-sklearn-1.0-ubuntu20.04-py38-cpu:1\n",
        "command: >-\n",
        "  python train.py \n",
        "  --train_data ${{inputs.train_data}} \n",
        "  --test_data ${{inputs.test_data}} \n",
        "  --learning_rate ${{inputs.learning_rate}}\n",
        "  --registered_model_name ${{inputs.registered_model_name}} \n",
        "  --model ${{outputs.model}}"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting ./components/train/train.yml\n"
        }
      ],
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import load_component\n",
        "\n",
        "train_component = load_component(\n",
        "    source=os.path.join(train_src_dir, \"train.yml\")\n",
        ")\n",
        "\n",
        "train_component = ml_client.create_or_update(train_component)\n",
        "\n",
        "print(\n",
        "    f\"Component {train_component.name} with Version {train_component.version} is registered\"\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\r\u001b[32mUploading train (0.0 MBs):   0%|          | 0/2898 [00:00<?, ?it/s]\r\u001b[32mUploading train (0.0 MBs): 100%|██████████| 2898/2898 [00:00<00:00, 64239.58it/s]\n\u001b[39m\n\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Component train_credit_defaults_model with Version 2024-07-06-04-41-32-0893536 is registered\n"
        }
      ],
      "execution_count": 27,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720240891958
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the pipeline from components"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import dsl, Input, Output\n",
        "\n",
        "@dsl.pipeline(\n",
        "    compute=\"serverless\", # \"serverless\" value runs pipeline on serverless compute\n",
        "    description=\"E2E data_perp-train pipeline\"\n",
        ")\n",
        "def credit_defaults_pipeline(\n",
        "    pipeline_job_data_input,\n",
        "    pipeline_job_test_train_ratio,\n",
        "    pipeline_job_learning_rate,\n",
        "    pipeline_job_registered_model_name\n",
        "):\n",
        "    data_prep_job = data_prep_component(\n",
        "        data=pipeline_job_data_input,\n",
        "        test_train_ratio=pipeline_job_test_train_ratio\n",
        "    )\n",
        "\n",
        "    train_job = train_component(\n",
        "        train_data=data_prep_job.outputs.train_data,\n",
        "        test_data=data_prep_job.outputs.test_data,\n",
        "        learning_rate=pipeline_job_learning_rate,\n",
        "        registered_model_name=pipeline_job_registered_model_name\n",
        "    )\n",
        "\n",
        "    # a pipeline returns a dictionary of outputs\n",
        "    # keys will code for the pipeline output identifier\n",
        "    return {\n",
        "        \"pipeline_job_train_data\": data_prep_job.outputs.train_data,\n",
        "        \"pipeline_job_test_data\": data_prep_job.outputs.test_data\n",
        "    }"
      ],
      "outputs": [],
      "execution_count": 28,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720240892059
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "registered_model_name = \"credit_defaults_model\"\n",
        "\n",
        "pipeline = credit_defaults_pipeline(\n",
        "    pipeline_job_data_input=Input(type=\"uri_file\", path=credit_data.path),\n",
        "    pipeline_job_test_train_ratio=0.25,\n",
        "    pipeline_job_learning_rate=0.05,\n",
        "    pipeline_job_registered_model_name=registered_model_name\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 29,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720240894155
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submit the job"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_job =  ml_client.jobs.create_or_update(\n",
        "    pipeline,\n",
        "    experiment_name=\"e2e_registered_components\"\n",
        ")\n",
        "ml_client.jobs.stream(pipeline_job.name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\npathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "RunId: strong_rod_tqlyg1ymg0\nWeb View: https://ml.azure.com/runs/strong_rod_tqlyg1ymg0?wsid=/subscriptions/a9ea30e6-5728-4375-ac04-cbe4918c3def/resourcegroups/rg-training/workspaces/ws-training\n\nStreaming logs/azureml/executionlogs.txt\n========================================\n\n[2024-07-06 04:41:43Z] Completing processing run id dc8a3102-6805-4b55-a478-a02ed0936366.\n[2024-07-06 04:41:44Z] Submitting 1 runs, first five are: f22cd48f:8e6a879f-06dc-494e-a634-e9f6df81aab3\n[2024-07-06 04:42:53Z] Completing processing run id 8e6a879f-06dc-494e-a634-e9f6df81aab3.\n\nExecution Summary\n=================\nRunId: strong_rod_tqlyg1ymg0\nWeb View: https://ml.azure.com/runs/strong_rod_tqlyg1ymg0?wsid=/subscriptions/a9ea30e6-5728-4375-ac04-cbe4918c3def/resourcegroups/rg-training/workspaces/ws-training\n\n"
        }
      ],
      "execution_count": 30,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720240983038
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}